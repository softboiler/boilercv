{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "::::\n",
    ":::{thebe-button}\n",
    ":::\n",
    "::::\n",
    "\n",
    "# Find tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "parameters",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Iterable\n",
    "from inspect import Signature\n",
    "\n",
    "from boilercv_pipeline.dfs import limit_group_size\n",
    "from boilercv_pipeline.models.column import Col, LinkedCol, convert, rename\n",
    "from boilercv_pipeline.models.deps import get_slices\n",
    "from boilercv_pipeline.models.df import GBC\n",
    "from boilercv_pipeline.models.params.types import DfOrS_T\n",
    "from boilercv_pipeline.models.path import get_datetime\n",
    "from boilercv_pipeline.models.subcool import const\n",
    "from boilercv_pipeline.palettes import cat10, cool\n",
    "from boilercv_pipeline.plotting import get_cat_colorbar\n",
    "from boilercv_pipeline.sets import inspect_video, load_video\n",
    "from boilercv_pipeline.stages import find_objects, get_thermal_data\n",
    "from boilercv_pipeline.stages.find_tracks import FindTracks as Params\n",
    "from boilercv_pipeline.units import U\n",
    "from dev.docs.nbs import get_mode, init\n",
    "from devtools import pprint\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import subplot_mosaic, subplots\n",
    "from more_itertools import one, only\n",
    "from numpy import diff, gradient, linalg, log10, logspace, pi, vectorize\n",
    "from pandas import DataFrame, Series, melt, merge_ordered, read_hdf\n",
    "from seaborn import lineplot, scatterplot\n",
    "from trackpy import link, quiet\n",
    "\n",
    "from boilercv.correlations import GROUPS\n",
    "from boilercv.correlations import beta as correlations_beta\n",
    "from boilercv.correlations import nusselt as correlations_nusselt\n",
    "from boilercv.correlations.types import Corr\n",
    "from boilercv.data import FRAME, TIME\n",
    "from boilercv.dimensionless_params import (\n",
    "    fourier,\n",
    "    jakob,\n",
    "    kinematic_viscosity,\n",
    "    nusselt,\n",
    "    prandtl,\n",
    "    reynolds,\n",
    "    thermal_diffusivity,\n",
    ")\n",
    "from boilercv.images import scale_bool\n",
    "\n",
    "quiet()\n",
    "\n",
    "PARAMS = None\n",
    "\"\"\"Notebook stage parameters.\"\"\"\n",
    "MODE = get_mode()\n",
    "\"\"\"Notebook execution mode.\"\"\"\n",
    "PREVIEW_FRAME_COUNT = 50\n",
    "\"\"\"Number of preview frames.\"\"\"\n",
    "Params.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "if isinstance(PARAMS, str):\n",
    "    params = Params.model_validate_json(PARAMS)\n",
    "elif MODE == \"docs\":\n",
    "    PREVIEW_FRAME_COUNT = 10\n",
    "    params = Params(\n",
    "        context=init(mode=MODE),\n",
    "        include_patterns=const.nb_include_patterns,\n",
    "        slicer_patterns=const.nb_slicer_patterns,\n",
    "    )\n",
    "else:\n",
    "    params = Params(context=init(mode=MODE), only_sample=True)\n",
    "params.set_display_options()\n",
    "data = params.data\n",
    "dfs = only(params.dfs)\n",
    "C = params.cols\n",
    "\n",
    "thermal = read_hdf(params.deps.thermal)\n",
    "TC = get_thermal_data.Cols()\n",
    "\n",
    "slices = get_slices(one(params.filled_slicers))\n",
    "frames_slice = slices.get(FRAME, slice(None))\n",
    "objects_path = one(params.objects)\n",
    "objects = read_hdf(objects_path).set_index(C.frame()).loc[frames_slice, :].reset_index()\n",
    "frames = objects[C.frame()].unique()\n",
    "OC = find_objects.Cols()\n",
    "\n",
    "filled_path = one(params.filled)\n",
    "with inspect_video(filled_path) as filled:\n",
    "    step_time = diff(filled[TIME].sel({FRAME: frames})[:2])[0]\n",
    "    objects = (\n",
    "        read_hdf(objects_path)\n",
    "        .set_index(C.frame())\n",
    "        .loc[frames_slice, :]\n",
    "        .reset_index()\n",
    "        .assign(**{\n",
    "            C.time_elapsed(): lambda df: filled.coords[TIME].sel({\n",
    "                FRAME: df[C.frame()].values\n",
    "            })\n",
    "        })\n",
    "    )\n",
    "\n",
    "\n",
    "time = get_datetime(objects_path.stem)\n",
    "subcooling = thermal.set_index(TC.time())[TC.subcool()][time]\n",
    "cols_to_link = [C.frame, OC.x_tp, OC.y_tp]\n",
    "\n",
    "# ! To find (202 - 96)\n",
    "# %matplotlib widget\n",
    "# from boilercv_pipeline.sets import get_dataset\n",
    "# _, ax = subplots()\n",
    "# ax.imshow(get_dataset(\"2024-07-18T17-44-35\", stage=\"large_sources\")[VIDEO].sel(frame=0))\n",
    "\n",
    "M_PER_PX = U.convert(3 / 8, \"in\", \"m\") / (202 - 96)\n",
    "# PX_PER_M = 20997.3753\n",
    "U.define(f\"px = {M_PER_PX} m\")\n",
    "U.define(f\"frames = {step_time} s\")\n",
    "\n",
    "# Physical parameters\n",
    "LATENT_HEAT_OF_VAPORIZATION = 2.23e6  # J/kg\n",
    "LIQUID_DENSITY = 960  # kg/m^3\n",
    "LIQUID_DYNAMIC_VISCOSITY = 2.88e-4  # Pa-s\n",
    "LIQUID_ISOBARIC_SPECIFIC_HEAT = 4213  # J/kg-K\n",
    "LIQUID_THERMAL_CONDUCTIVITY = 0.676  # W/m-K\n",
    "VAPOR_DENSITY = 0.804  # kg/m^3\n",
    "\n",
    "\n",
    "# Plotting\n",
    "groups = {C.corr[k](): v for k, v in GROUPS.items() if k in C.corr}\n",
    "\"\"\"Groups for mapping to correlations in data.\"\"\"\n",
    "GROUP_DRAW_ORDER = [\"Group 2\", \"Group 4\", \"Group 3\", \"Group 1\", \"Ours\"]  # , \"Group 5\"]\n",
    "\"\"\"Order to draw groups.\"\"\"\n",
    "GROUP_ORDER = sorted(GROUP_DRAW_ORDER)\n",
    "\"\"\"Order to show groups in legend.\"\"\"\n",
    "GROUP_SORTER = vectorize(GROUP_DRAW_ORDER.index)\n",
    "\"\"\"Sorter for groups.\"\"\"\n",
    "CORRELATIONS_PALETTE = cat10\n",
    "\"\"\"For plotting one approach.\"\"\"\n",
    "TRACKS_PALETTE = cool\n",
    "\"\"\"For plotting the other approach.\"\"\"\n",
    "MAX_FOURIER = 0.005\n",
    "\"\"\"Maximum Fourier number to plot.\"\"\"\n",
    "MAX_BETA = 1.05\n",
    "\"\"\"Maximum dimensionless bubble diameter to plot.\"\"\"\n",
    "MAX_NUSSELT = 1000\n",
    "\"\"\"Maximum Nusselt number to plot.\"\"\"\n",
    "TRACKS_ALPHA = 0.1\n",
    "\"\"\"Transparency of the tracks.\"\"\"\n",
    "TRACKS_SIZE = 10\n",
    "\"\"\"Size of the tracks.\"\"\"\n",
    "MAX_BETA_MAE = 0.3\n",
    "\"\"\"Maximum mean absolute error of beta to plot.\"\"\"\n",
    "MAX_NUSSELT_ERR = 12000\n",
    "\"\"\"Maximum mean absolute error of nusselt to plot.\"\"\"\n",
    "WIDTH_SCALE = 1.48  # 1.215  # 1.48\n",
    "\"\"\"Width to scale plots by.\"\"\"\n",
    "HEIGHT_SCALE = 1.000\n",
    "\"\"\"Width to scale plots by.\"\"\"\n",
    "\n",
    "\n",
    "def scale_figure(fig: Figure, width: float = WIDTH_SCALE, height: float = HEIGHT_SCALE):\n",
    "    \"\"\"Scale up figure size.\"\"\"\n",
    "    fig.set_figwidth(width * fig.get_figwidth())\n",
    "    fig.set_figheight(height * fig.get_figheight())\n",
    "\n",
    "\n",
    "def get_delta(df: DataFrame, c: LinkedCol) -> Series[float]:\n",
    "    \"\"\"Get position time delta across frames.\"\"\"\n",
    "    return df.groupby(C.bub(), **GBC)[[c.source()]].diff().fillna(0) / step_time\n",
    "\n",
    "\n",
    "# def query_lifetime(df: DataFrame) -> DataFrame:\n",
    "#     \"\"\"Filter bubbles by lifetime.\"\"\"\n",
    "#     return (\n",
    "#         df.rename(columns={C.bub_visible(): (temp_name := C.bub_visible.no_unit.name)})\n",
    "#         .query(f\"`{temp_name}` > {MINIMUM_LIFETIME}\")\n",
    "#         .rename(columns={temp_name: C.bub_visible()})\n",
    "#     )\n",
    "\n",
    "\n",
    "beta_correlations = correlations_beta.get_correlations()\n",
    "nusselt_correlations = correlations_nusselt.get_correlations()\n",
    "constants = {\n",
    "    \"Ja\": jakob(\n",
    "        liquid_density=LIQUID_DENSITY,\n",
    "        vapor_density=VAPOR_DENSITY,\n",
    "        liquid_isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        subcooling=subcooling,\n",
    "        latent_heat_of_vaporization=LATENT_HEAT_OF_VAPORIZATION,\n",
    "    ),\n",
    "    \"Pr\": prandtl(\n",
    "        dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "    ),\n",
    "    \"alpha\": 1.0,\n",
    "    \"pi\": pi,\n",
    "    \"liquid_kinematic_viscosity\": kinematic_viscosity(\n",
    "        density=LIQUID_DENSITY, dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY\n",
    "    ),\n",
    "    \"liquid_thermal_diffusivity\": thermal_diffusivity(\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "        density=LIQUID_DENSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "    ),\n",
    "    \"liquid_prandtl\": prandtl(\n",
    "        dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def get_corrs(df: DataFrame, kind: Corr) -> DataFrame:\n",
    "    \"\"\"Get correlations.\"\"\"\n",
    "    return df.assign(**{\n",
    "        C.corr[label](): (\n",
    "            corr.expr(**{\n",
    "                kwd: value\n",
    "                for kwd, value in {\n",
    "                    **constants,\n",
    "                    \"Re_b\": df[C.bub_reynolds()],\n",
    "                    \"Re_b0\": df[C.bub_reynolds0()],\n",
    "                    \"Fo_0\": df[C.bub_fourier()],\n",
    "                    **({} if kind == \"beta\" else {\"beta\": df[C.bub_beta()]}),\n",
    "                }.items()\n",
    "                if kwd in Signature.from_callable(corr.expr).parameters\n",
    "            })\n",
    "        )\n",
    "        for label, corr in (\n",
    "            beta_correlations if kind == \"beta\" else nusselt_correlations\n",
    "        ).items()\n",
    "    })\n",
    "\n",
    "\n",
    "def get_error(df: DataFrame, kind: Corr, rel: bool = True) -> DataFrame:\n",
    "    \"\"\"Get error.\"\"\"\n",
    "    corrs = [c() for c in C.corr.values()]\n",
    "    exp = C.bub_beta() if kind == \"beta\" else C.bub_nusselt()\n",
    "    return (\n",
    "        df.set_index([C.bub_fourier(), C.bub()])[[exp, *corrs]]\n",
    "        .pipe(\n",
    "            lambda df: df.assign(**{\n",
    "                c: abs(df[exp] - df[c]) / (df[c] if rel else 1) for c in corrs\n",
    "            })\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def set_group_legend(\n",
    "    fig: Figure,\n",
    "    ax: Axes,\n",
    "    loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 1.0),\n",
    "    ncol=5,\n",
    "    width=WIDTH_SCALE,\n",
    "    height=HEIGHT_SCALE,\n",
    "):\n",
    "    \"\"\"Set legend for correlation groups.\"\"\"\n",
    "    legend = ax.legend(\n",
    "        [\n",
    "            {\n",
    "                lab: h\n",
    "                for h, lab in zip(*ax.get_legend_handles_labels(), strict=False)\n",
    "                if \"Group\" in lab or \"Ours\" in lab\n",
    "            }[lab]\n",
    "            for lab in GROUP_ORDER\n",
    "        ],\n",
    "        GROUP_ORDER,\n",
    "        loc=loc,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        ncol=ncol,\n",
    "    )\n",
    "    for handle in legend.legend_handles:  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        handle.set_alpha(1.0)\n",
    "    scale_figure(fig, width=width, height=height)\n",
    "\n",
    "\n",
    "def preview(\n",
    "    df: DfOrS_T,\n",
    "    cols: Iterable[Col] | None = None,\n",
    "    index: Col | None = None,\n",
    "    f: Callable[[DfOrS_T], DfOrS_T] | None = None,\n",
    "    ncol: int = 0,\n",
    ") -> DfOrS_T:\n",
    "    \"\"\"Preview a dataframe in the notebook.\"\"\"\n",
    "    # fmt: off\n",
    "    if df.empty:\n",
    "        display(df)\n",
    "        return df\n",
    "    if isinstance(df, Series):\n",
    "        def _f(df): return (f(df) if f else df).head(16)\n",
    "    elif C.bub() in df.columns:\n",
    "        def _f(df): return (_df := f(df) if f else df).groupby(C.bub(), **GBC)[_df.columns].head(4).head(16)  # pyright: ignore[reportRedeclaration]\n",
    "    else:\n",
    "        def _f(df): return (f(df) if f else df).head(4).head(16)\n",
    "    # fmt: on\n",
    "    df = params.preview(cols=cols, df=df, index=index, f=_f, ncol=ncol)  # pyright: ignore[reportArgumentType]\n",
    "    return df\n",
    "\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Linking\n",
    "SEARCH_RANGE = 10\n",
    "\"\"\"Pixel range to search for the next bubble.\"\"\"\n",
    "MEMORY = 100\n",
    "\"\"\"Frames to remember a bubble.\"\"\"\n",
    "length = MEMORY // 2\n",
    "\n",
    "# Track tuning\n",
    "Y_SURFACE_THRESHOLD = U.convert(250, \"px\", \"m\")\n",
    "\"\"\"Vertical position of bubble centroids considered attached to the surface.\"\"\"\n",
    "Y_DEPARTURE_THRESHOLD = U.convert(280, \"px\", \"m\")\n",
    "\"\"\"Vertical position of bubble centroids considered to have departed the surface.\"\"\"\n",
    "# MINIMUM_LIFETIME = 0.01  # 0.005  # s\n",
    "# \"\"\"Minimum bubble lifetime to consider.\"\"\"\n",
    "\n",
    "\n",
    "def get_init(ser: Series[float], tail: bool = False) -> float:\n",
    "    \"\"\"Get initial value of a series.\"\"\"\n",
    "    return ser.tail(length).median() if tail else ser.head(length).median()\n",
    "\n",
    "\n",
    "data.dfs.tracks = preview(\n",
    "    ncol=12,\n",
    "    cols=C.tracks,\n",
    "    df=link(\n",
    "        # ? TrackPy expects certain column names\n",
    "        f=objects.rename(columns={c(): c.source.raw for c in cols_to_link}),  # pyright: ignore[reportCallIssue]\n",
    "        search_range=SEARCH_RANGE,\n",
    "        memory=MEMORY,\n",
    "    )\n",
    "    .pipe(rename, cols_to_link)  # ? Back to our names\n",
    "    .pipe(C.bub.rename)\n",
    "    .assign(**{\n",
    "        C.bub_visible_frames(): lambda df: (\n",
    "            df.groupby(C.bub(), **GBC)[C.bub()].transform(\"count\") * frames_slice.step\n",
    "        )\n",
    "    })\n",
    "    .pipe(convert, [C.x, C.y, C.diameter, C.radius_of_gyration], U)\n",
    "    .sort_values(\n",
    "        [C.bub_visible_frames(), C.bub(), C.frame()], ascending=[False, True, True]\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): (lambda df: df.groupby(C.bub(), **GBC).ngroup()),\n",
    "        C.u(): lambda df: get_delta(df, C.u),\n",
    "        C.v(): lambda df: get_delta(df, C.v),\n",
    "        C.distance(): lambda df: linalg.norm(df[[C.x(), C.y()]].abs(), axis=1),\n",
    "    })\n",
    "    .pipe(convert, [C.bub_visible], U),\n",
    ")\n",
    "print(f\"Found {data.dfs.tracks[C.bub()].nunique()} bubbles\")\n",
    "data.dfs.bubbles = preview(\n",
    "    ncol=12,\n",
    "    cols=C.bubbles,\n",
    "    # ? Find rows corresponding to stagnant or invalid bubbles\n",
    "    # .pipe(lambda df: df[df[C.bub_visible()] > MINIMUM_LIFETIME])\n",
    "    df=data.dfs.tracks.groupby(C.bub(), **GBC)[data.dfs.tracks.columns]\n",
    "    # .apply(lambda df: df[(df[C.v()] > -0.1) & (df[C.v()] < 0.1)])\n",
    "    .apply(\n",
    "        # ? Don't assign any other columns until invalid rows have been filtered out\n",
    "        lambda df: df.assign(**{\n",
    "            \"bubble_visible_y\": lambda df: df[C.y()].pipe(get_init),\n",
    "            # ? Initial y position is close to the surface\n",
    "            \"began\": lambda df: df[\"bubble_visible_y\"] > Y_SURFACE_THRESHOLD,\n",
    "            # ? When the bubble gets far enough away from the surface\n",
    "            \"departed\": lambda df: df[C.y()] < Y_DEPARTURE_THRESHOLD,\n",
    "        })\n",
    "    )\n",
    "    # ? Filter out invalid rows\n",
    "    .pipe(lambda df: df[df[\"began\"] & df[\"departed\"]])\n",
    "    .pipe(limit_group_size, C.bub(), 1)\n",
    "    # ? Groupby again after filtering out invalid rows\n",
    "    .groupby(C.bub(), **GBC)[data.dfs.tracks.columns]\n",
    "    # ? Now columns that depend on the initial row (*.iat[0]) can be assigned\n",
    "    .apply(\n",
    "        lambda df: df.assign(**{\n",
    "            C.bub_time(): lambda df: (\n",
    "                df[C.time_elapsed()] - df[C.time_elapsed()].iat[0]\n",
    "            ),\n",
    "            C.bub_lifetime(): lambda df: (\n",
    "                df[C.bub_time()].iat[-1] - df[C.bub_time()].iat[0]\n",
    "            ),\n",
    "        })\n",
    "    )\n",
    "    # .pipe(lambda df: df[df[C.bub_time()] > 0])\n",
    "    .groupby(C.bub(), **GBC)[[C.bub_time(), C.bub_lifetime(), *data.dfs.tracks.columns]]\n",
    "    # ? Now columns that depend on the initial row (*.iat[0]) can be assigned\n",
    "    .apply(\n",
    "        lambda df: df.assign(**{\n",
    "            C.bub_t0(): lambda df: df[C.bub_time()].pipe(get_init),\n",
    "            C.bub_x0(): lambda df: df[C.x()].pipe(get_init),\n",
    "            C.bub_y0(): lambda df: df[C.y()].pipe(get_init),\n",
    "            C.bub_d0(): lambda df: df[C.diameter()].pipe(get_init),\n",
    "            C.bub_u0(): lambda df: df[C.u()].pipe(get_init),\n",
    "            C.bub_v0(): lambda df: df[C.v()].pipe(get_init),\n",
    "            C.max_diam(): lambda df: df[C.diameter()].max(),\n",
    "            C.diam_rate_of_change(): lambda df: gradient(\n",
    "                df[C.diameter()], df[C.bub_time()]\n",
    "            ),\n",
    "        })\n",
    "    )\n",
    "    .assign(**{\"y\": lambda df: df[C.y()] - df[C.bub_y0()]})[[c() for c in C.bubbles]],\n",
    ")\n",
    "print(f\"{data.dfs.bubbles[C.bub()].nunique()} bubbles remain\")\n",
    "data.plots.bubbles, ax = subplots()\n",
    "ax.set_xlabel(C.x())\n",
    "ax.set_ylabel(C.y())\n",
    "with load_video(\n",
    "    filled_path, slices={FRAME: frames[:: (len(frames) // PREVIEW_FRAME_COUNT)]}\n",
    ") as video:\n",
    "    composite_video = scale_bool(video).max(FRAME).values\n",
    "    height, width = composite_video.shape[:2]\n",
    "    ax.imshow(\n",
    "        ~composite_video, alpha=0.6, extent=(0, width * M_PER_PX, height * M_PER_PX, 0)\n",
    "    )\n",
    "palette, _ = get_cat_colorbar(\n",
    "    ax, palette=TRACKS_PALETTE, data=data.dfs.bubbles, col=C.bub()\n",
    ")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    x=C.x(),\n",
    "    y=C.y(),\n",
    "    hue=C.bub(),\n",
    "    legend=False,\n",
    "    palette=palette,\n",
    "    data=data.dfs.bubbles.assign(**{c: data.dfs.tracks[c] for c in [C.x(), C.y()]}),\n",
    ")\n",
    "data.plots.multi, axs = subplot_mosaic([[C.y()], [C.diameter()]])\n",
    "scale_figure(data.plots.multi, height=2 * HEIGHT_SCALE)\n",
    "for plot, ax in axs.items():\n",
    "    if plot in [C.v(), C.diam_rate_of_change()]:  # pyright: ignore[reportUnnecessaryContains]  # TODO: Fix this upstream\n",
    "        ax.set_yscale(\"log\")\n",
    "    palette, _ = get_cat_colorbar(ax, C.bub(), TRACKS_PALETTE, data.dfs.bubbles)\n",
    "    scatterplot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"none\",\n",
    "        s=TRACKS_SIZE,\n",
    "        alpha=TRACKS_ALPHA,\n",
    "        x=C.bub_time(),\n",
    "        y=plot,  # pyright: ignore[reportArgumentType] 1.1.356\n",
    "        hue=C.bub(),\n",
    "        legend=False,\n",
    "        palette=palette,\n",
    "        data=data.dfs.bubbles.assign(**{  # pyright: ignore[reportCallIssue]\n",
    "            c: data.dfs.tracks[c] for c in axs if c not in data.dfs.bubbles.columns\n",
    "        }),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.dst = preview(\n",
    "    cols=C.dests,\n",
    "    df=data.dfs.bubbles.assign(**{\n",
    "        C.bub_reynolds(): reynolds(\n",
    "            velocity=abs(data.dfs.tracks[C.v()]),\n",
    "            characteristic_length=data.dfs.tracks[C.diameter()],\n",
    "            kinematic_viscosity=constants[\"liquid_kinematic_viscosity\"],\n",
    "        ),\n",
    "        C.bub_reynolds0(): lambda df: df.groupby(C.bub(), **GBC)[\n",
    "            C.bub_reynolds()\n",
    "        ].transform(get_init),\n",
    "        C.bub_fourier(): fourier(\n",
    "            initial_bubble_diameter=data.dfs.bubbles[C.bub_d0()],\n",
    "            liquid_thermal_diffusivity=constants[\"liquid_thermal_diffusivity\"],\n",
    "            time=data.dfs.bubbles[C.bub_time()],\n",
    "        ),\n",
    "        C.bub_nusselt(): nusselt(  # Nu_c\n",
    "            heat_transfer_coefficient=-(\n",
    "                2\n",
    "                * VAPOR_DENSITY\n",
    "                * LATENT_HEAT_OF_VAPORIZATION\n",
    "                / subcooling\n",
    "                * data.dfs.bubbles[C.diam_rate_of_change()]\n",
    "            ),\n",
    "            characteristic_length=data.dfs.tracks[C.diameter()] / 2,\n",
    "            thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "        ),\n",
    "        C.bub_beta(): (lambda df: data.dfs.tracks[C.diameter()] / df[C.bub_d0()]),\n",
    "    })[[c() for c in C.dests]],\n",
    "    # .pipe(\n",
    "    #     lambda df: df[\n",
    "    #         (df[C.bub_beta()] > 0)\n",
    "    #         & (df[C.bub_beta()] < MAX_BETA)\n",
    "    #         & (df[C.bub_nusselt()] > 0)\n",
    "    #         & (df[C.bub_nusselt()] < MAX_NUSSELT)\n",
    "    #         & (df[C.bub_fourier()] < MAX_FOURIER)\n",
    "    #     ]\n",
    "    # )\n",
    ")\n",
    "print(f\"{data.dfs.dst[C.bub()].nunique()} bubbles remain\")\n",
    "data.dfs.beta = preview(\n",
    "    cols=C.corr_beta, df=data.dfs.dst.pipe(get_corrs, kind=\"beta\"), ncol=6\n",
    ")[[c() for c in C.corr_beta]]\n",
    "data.dfs.nusselt = preview(\n",
    "    cols=C.corr_nusselt, df=data.dfs.dst.pipe(get_corrs, kind=\"nusselt\"), ncol=6\n",
    ")[[c() for c in C.corr_nusselt]]\n",
    "data.dfs.beta_err = preview(\n",
    "    cols=C.corr_beta, df=data.dfs.beta.pipe(get_error, kind=\"beta\"), ncol=6\n",
    ")[[c() for c in C.err_beta]]\n",
    "data.dfs.nusselt_err = preview(\n",
    "    cols=C.corr_nusselt, df=data.dfs.nusselt.pipe(get_error, kind=\"nusselt\"), ncol=6\n",
    ")[[c() for c in C.err_nusselt]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    c()\n",
    "    for k, c in C.corr.items()\n",
    "    if k\n",
    "    in [\n",
    "        \"naccarato_kim_2024\",\n",
    "        \"florschuetz_chao_1965\",\n",
    "        \"isenberg_sideman_1970\",  # a\n",
    "        \"akiyama_1973\",\n",
    "        \"chen_mayinger_1992\",  # a\n",
    "        \"zeitoun_et_al_1995\",\n",
    "        \"kalman_mori_2002\",\n",
    "        \"warrier_et_al_2002\",  # a\n",
    "        \"yuan_et_al_2009\",  # a\n",
    "        \"lucic_mayinger_2010\",\n",
    "        \"kim_park_2011\",  # a\n",
    "        \"al_issa_et_al_2014\",  # a\n",
    "        \"tang_et_al_2016\",  # a\n",
    "    ]\n",
    "]\n",
    "data.plots.beta, ax = subplots()\n",
    "palette, _ = get_cat_colorbar(\n",
    "    ax, palette=TRACKS_PALETTE, data=data.dfs.dst, col=C.bub()\n",
    ")\n",
    "ax.set_xlim(0, min(MAX_FOURIER, data.dfs.dst[C.bub_fourier()].max()))\n",
    "ax.set_ylim(0, MAX_BETA)\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    s=TRACKS_SIZE,\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_beta(),\n",
    "    hue=C.bub(),\n",
    "    legend=False,\n",
    "    palette=palette,\n",
    "    data=data.dfs.dst,\n",
    ")\n",
    "beta = get_corrs(\n",
    "    DataFrame({\n",
    "        C.bub_fourier(): logspace(\n",
    "            stop=log10(MAX_FOURIER), start=log10(MAX_FOURIER) - 4, num=int(1e4)\n",
    "        ),\n",
    "        C.bub_reynolds0(): data.dfs.dst[C.bub_reynolds0()].median(),\n",
    "        C.bub_reynolds(): data.dfs.dst[C.bub_reynolds()].median(),\n",
    "    }),\n",
    "    \"beta\",\n",
    ")\n",
    "lineplot(\n",
    "    ax=ax,\n",
    "    palette=CORRELATIONS_PALETTE,\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_beta(),\n",
    "    dashes=False,\n",
    "    style=\"Correlation\",\n",
    "    hue=\"Group\",\n",
    "    errorbar=None,\n",
    "    data=(\n",
    "        melt(\n",
    "            beta.set_index(C.bub_fourier())[cols],\n",
    "            var_name=\"Correlation\",\n",
    "            value_name=C.bub_beta(),\n",
    "            value_vars=cols,\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .assign(**{\n",
    "            C.bub_fourier(): lambda df: df.index,\n",
    "            \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"Group\")\n",
    "    ),\n",
    ")\n",
    "set_group_legend(data.plots.beta, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.plots.beta_err, ax = subplots()\n",
    "ax.set_ylabel(C.bub_beta())\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_beta(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        melt(\n",
    "            data.dfs.beta_err.set_index(C.bub_fourier())[\n",
    "                [c() for c in C.corr.values()]\n",
    "            ],\n",
    "            var_name=\"Correlation\",\n",
    "            value_name=C.bub_beta(),\n",
    "            value_vars=[c() for c in C.corr.values()],\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .assign(**{\n",
    "            C.bub_fourier(): lambda df: df.index,\n",
    "            \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(data.plots.beta_err, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.plots.nusselt_err, ax = subplots()\n",
    "ax.set_ylabel(C.bub_nusselt())\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_nusselt(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        melt(\n",
    "            data.dfs.nusselt_err.set_index(C.bub_fourier())[\n",
    "                [c() for c in C.corr.values()]\n",
    "            ],\n",
    "            var_name=\"Correlation\",\n",
    "            value_name=C.bub_nusselt(),\n",
    "            value_vars=[c() for c in C.corr.values()],\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .assign(**{\n",
    "            C.bub_fourier(): lambda df: df.index,\n",
    "            \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(data.plots.nusselt_err, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pivoted_beta_err = (\n",
    "    melt(\n",
    "        data.dfs.beta.groupby(C.bub(), **GBC)[[c() for c in C.corr.values()]]\n",
    "        .apply(lambda df: df.sum() / len(df))\n",
    "        .set_index(C.bub()),\n",
    "        var_name=\"Correlation\",\n",
    "        value_name=C.bub_beta(),\n",
    "        value_vars=[c() for c in C.corr.values()],\n",
    "        ignore_index=False,\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): lambda df: df.index,\n",
    "        \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(\"Group\")\n",
    ")\n",
    "pivoted_nusselt_err = (\n",
    "    melt(\n",
    "        data.dfs.nusselt.groupby(C.bub(), **GBC)[[c() for c in C.corr.values()]]\n",
    "        .apply(lambda df: df.sum() / len(df))\n",
    "        .set_index(C.bub()),\n",
    "        var_name=\"Correlation\",\n",
    "        value_name=C.bub_nusselt(),\n",
    "        value_vars=[c() for c in C.corr.values()],\n",
    "        ignore_index=False,\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): lambda df: df.index,\n",
    "        \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(\"Group\")\n",
    ")\n",
    "data.plots.mae, ax = subplots()\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA * 3,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_beta(),\n",
    "    y=C.bub_nusselt(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        merge_ordered(\n",
    "            pivoted_beta_err.drop(columns=\"Group\").set_index(C.bub()),\n",
    "            pivoted_nusselt_err.drop(columns=\"Group\").set_index(C.bub()),\n",
    "            on=[C.bub(), \"Correlation\"],\n",
    "        )\n",
    "        .assign(**{\"Group\": lambda df: df[\"Correlation\"].map(groups)})\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(data.plots.mae, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "parameters": {
    "product": "C:/Users/Blake/Code/mine/boilercv/data/docs/study_the_fit_of_bubble_collapse_correlations/prove_the_concept/23-07-13T14_full_video.ipynb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
