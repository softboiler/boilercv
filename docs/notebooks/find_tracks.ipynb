{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "::::\n",
    ":::{thebe-button}\n",
    ":::\n",
    "::::\n",
    "\n",
    "# Find tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "parameters",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Iterable\n",
    "from datetime import datetime\n",
    "from inspect import Signature\n",
    "\n",
    "from boilercore.paths import ISOLIKE, dt_fromisolike\n",
    "from boilercv_pipeline.dfs import limit_group_size\n",
    "from boilercv_pipeline.models.column import Col, LinkedCol, convert, rename\n",
    "from boilercv_pipeline.models.deps import get_slices\n",
    "from boilercv_pipeline.models.df import GBC\n",
    "from boilercv_pipeline.models.params.types import DfOrS_T\n",
    "from boilercv_pipeline.models.subcool import const\n",
    "from boilercv_pipeline.palettes import cat10, cool\n",
    "from boilercv_pipeline.plotting import get_cat_colorbar\n",
    "from boilercv_pipeline.sets import inspect_video\n",
    "from boilercv_pipeline.stages import find_objects, get_thermal_data\n",
    "from boilercv_pipeline.stages.find_tracks import FindTracks as Params\n",
    "from boilercv_pipeline.units import U\n",
    "from dev.docs.nbs import init\n",
    "from devtools import pprint\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import subplot_mosaic, subplots\n",
    "from more_itertools import one, only\n",
    "from numpy import diff, gradient, linalg, pi, vectorize\n",
    "from pandas import DataFrame, Series, melt, merge_ordered, read_hdf\n",
    "from seaborn import scatterplot\n",
    "from trackpy import link, quiet\n",
    "\n",
    "from boilercv.correlations import GROUPS\n",
    "from boilercv.correlations import beta as correlations_beta\n",
    "from boilercv.correlations import nusselt as correlations_nusselt\n",
    "from boilercv.correlations.types import Corr\n",
    "from boilercv.data import FRAME, TIME, VIDEO\n",
    "from boilercv.dimensionless_params import (\n",
    "    fourier,\n",
    "    jakob,\n",
    "    kinematic_viscosity,\n",
    "    nusselt,\n",
    "    prandtl,\n",
    "    reynolds,\n",
    "    thermal_diffusivity,\n",
    ")\n",
    "\n",
    "quiet()\n",
    "\n",
    "PARAMS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "if isinstance(PARAMS, str):\n",
    "    params = Params.model_validate_json(PARAMS)\n",
    "else:\n",
    "    params = Params(\n",
    "        context=init(),\n",
    "        include_patterns=const.nb_include_patterns,\n",
    "        slicer_patterns=const.nb_slicer_patterns,\n",
    "    )\n",
    "context = params.context\n",
    "params.set_display_options()\n",
    "data = params.data\n",
    "C = params.cols\n",
    "\n",
    "slices = get_slices(one(params.filled_slicers))\n",
    "objects_path = one(params.objects)\n",
    "objects = (\n",
    "    read_hdf(objects_path)\n",
    "    .set_index(C.frame())\n",
    "    .loc[slices.get(FRAME, slice(None)), :]\n",
    "    .reset_index()\n",
    ")\n",
    "frames = slices.get(FRAME, slice(None))\n",
    "OC = find_objects.Cols()\n",
    "\n",
    "with inspect_video(one(params.filled)) as src:\n",
    "    filled = src[VIDEO]\n",
    "    slices = get_slices(one(params.filled_slicers))\n",
    "    objects = (\n",
    "        read_hdf(objects_path)\n",
    "        .set_index(C.frame())\n",
    "        .loc[frames, :]\n",
    "        .reset_index()\n",
    "        .assign(**{\n",
    "            C.time_elapsed(): lambda df: src.coords[TIME].sel({\n",
    "                FRAME: df[C.frame()].values\n",
    "            })\n",
    "        })\n",
    "    )\n",
    "    step_time = diff(src[FRAME].sel({FRAME: objects[C.frame()].unique()})[:2])[0]\n",
    "\n",
    "dfs = only(params.dfs)\n",
    "\n",
    "thermal = read_hdf(params.deps.thermal)\n",
    "TC = get_thermal_data.Cols()\n",
    "\n",
    "\n",
    "def get_time() -> datetime:\n",
    "    \"\"\"Get time from path.\"\"\"\n",
    "    if match := ISOLIKE.search(objects_path.stem):\n",
    "        return dt_fromisolike(match)\n",
    "    else:\n",
    "        raise ValueError(\"No time found in path.\")\n",
    "\n",
    "\n",
    "time = get_time()\n",
    "subcooling = thermal.set_index(TC.time())[TC.subcool()][time]\n",
    "\n",
    "frames_per_step = frames.step\n",
    "time_per_frame = step_time / frames_per_step\n",
    "\n",
    "cols_to_link = [C.frame, OC.x_tp, OC.y_tp]\n",
    "\n",
    "# ! To find (202 - 96)\n",
    "# %matplotlib widget\n",
    "# from boilercv_pipeline.sets import get_dataset\n",
    "# _, ax = subplots()\n",
    "# ax.imshow(get_dataset(\"2024-07-18T17-44-35\", stage=\"large_sources\")[VIDEO].sel(frame=0))\n",
    "\n",
    "M_PER_PX = U.convert(3 / 8, \"in\", \"m\") / (202 - 96)\n",
    "# PX_PER_M = 20997.3753\n",
    "U.define(f\"px = {M_PER_PX} m\")\n",
    "U.define(f\"frames = {time_per_frame} s\")\n",
    "\n",
    "# Linking\n",
    "SEARCH_RANGE = 5 * frames_per_step\n",
    "\"\"\"Pixel range to search for the next bubble.\"\"\"\n",
    "MEMORY = 5 * frames_per_step\n",
    "\"\"\"Frames to remember a bubble.\"\"\"\n",
    "\n",
    "# Track tuning\n",
    "Y_SURFACE_THRESHOLD = U.convert(280, \"px\", \"m\")\n",
    "\"\"\"Vertical position of bubble centroids considered attached to the surface.\"\"\"\n",
    "Y_DEPARTURE_THRESHOLD = U.convert(300, \"px\", \"m\")\n",
    "\"\"\"Vertical position of bubble centroids considered to have departed the surface.\"\"\"\n",
    "MINIMUM_LIFETIME = 0.005  # s\n",
    "\"\"\"Minimum bubble lifetime to consider.\"\"\"\n",
    "\n",
    "# Physical parameters\n",
    "LATENT_HEAT_OF_VAPORIZATION = 2.23e6  # J/kg\n",
    "LIQUID_DENSITY = 960  # kg/m^3\n",
    "LIQUID_DYNAMIC_VISCOSITY = 2.88e-4  # Pa-s\n",
    "LIQUID_ISOBARIC_SPECIFIC_HEAT = 4213  # J/kg-K\n",
    "LIQUID_THERMAL_CONDUCTIVITY = 0.676  # W/m-K\n",
    "VAPOR_DENSITY = 0.804  # kg/m^3\n",
    "\n",
    "\n",
    "# Plotting\n",
    "groups = {C.corr[k](): v for k, v in GROUPS.items() if k in C.corr}\n",
    "\"\"\"Groups for mapping to correlations in data.\"\"\"\n",
    "GROUP_DRAW_ORDER = [\"Group 2\", \"Group 4\", \"Group 3\", \"Group 1\"]\n",
    "\"\"\"Order to draw groups.\"\"\"\n",
    "GROUP_ORDER = sorted(GROUP_DRAW_ORDER)\n",
    "\"\"\"Order to show groups in legend.\"\"\"\n",
    "GROUP_SORTER = vectorize(GROUP_DRAW_ORDER.index)\n",
    "\"\"\"Sorter for groups.\"\"\"\n",
    "CORRELATIONS_PALETTE = cat10\n",
    "\"\"\"For plotting one approach.\"\"\"\n",
    "TRACKS_PALETTE = cool\n",
    "\"\"\"For plotting the other approach.\"\"\"\n",
    "MAX_FOURIER = 0.005\n",
    "\"\"\"Maximum Fourier number to plot.\"\"\"\n",
    "MAX_BETA = 1.05\n",
    "\"\"\"Maximum dimensionless bubble diameter to plot.\"\"\"\n",
    "MAX_NUSSELT = 1000\n",
    "\"\"\"Maximum Nusselt number to plot.\"\"\"\n",
    "TRACKS_ALPHA = 0.4\n",
    "\"\"\"Transparency of the tracks.\"\"\"\n",
    "TRACKS_SIZE = 10\n",
    "\"\"\"Size of the tracks.\"\"\"\n",
    "MAX_BETA_MAE = 0.3\n",
    "\"\"\"Maximum mean absolute error of beta to plot.\"\"\"\n",
    "MAX_NUSSELT_ERR = 12000\n",
    "\"\"\"Maximum mean absolute error of nusselt to plot.\"\"\"\n",
    "WIDTH_SCALE = 1.89\n",
    "\"\"\"Width to scale plots by.\"\"\"\n",
    "HEIGHT_SCALE = 1.30\n",
    "\"\"\"Width to scale plots by.\"\"\"\n",
    "\n",
    "\n",
    "def scale_figure(fig: Figure, width: float = WIDTH_SCALE, height: float = HEIGHT_SCALE):\n",
    "    \"\"\"Scale up figure size.\"\"\"\n",
    "    fig.set_figwidth(width * fig.get_figwidth())\n",
    "    fig.set_figheight(height * fig.get_figheight())\n",
    "\n",
    "\n",
    "def get_init(ser: Series[float]) -> float:\n",
    "    \"\"\"Get initial value of a series.\"\"\"\n",
    "    return ser.head(int(MINIMUM_LIFETIME // step_time) or 1).median()\n",
    "\n",
    "\n",
    "def get_delta(df: DataFrame, c: LinkedCol) -> Series[float]:\n",
    "    \"\"\"Get position time delta across frames.\"\"\"\n",
    "    return df.groupby(C.bub(), **GBC)[[c.source()]].diff().fillna(0) / step_time\n",
    "\n",
    "\n",
    "def query_lifetime(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Filter bubbles by lifetime.\"\"\"\n",
    "    return (\n",
    "        df.rename(columns={C.bub_visible(): (temp_name := C.bub_visible.no_unit.name)})\n",
    "        .query(f\"`{temp_name}` > {MINIMUM_LIFETIME}\")\n",
    "        .rename(columns={temp_name: C.bub_visible()})\n",
    "    )\n",
    "\n",
    "\n",
    "beta_correlations = correlations_beta.get_correlations()\n",
    "nusselt_correlations = correlations_nusselt.get_correlations()\n",
    "constants = {\n",
    "    \"Ja\": jakob(\n",
    "        liquid_density=LIQUID_DENSITY,\n",
    "        vapor_density=VAPOR_DENSITY,\n",
    "        liquid_isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        subcooling=subcooling,\n",
    "        latent_heat_of_vaporization=LATENT_HEAT_OF_VAPORIZATION,\n",
    "    ),\n",
    "    \"Pr\": prandtl(\n",
    "        dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "    ),\n",
    "    \"alpha\": thermal_diffusivity(\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "        density=LIQUID_DENSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "    ),\n",
    "    \"pi\": pi,\n",
    "    \"liquid_kinematic_viscosity\": kinematic_viscosity(\n",
    "        density=LIQUID_DENSITY, dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY\n",
    "    ),\n",
    "    \"liquid_thermal_diffusivity\": thermal_diffusivity(\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "        density=LIQUID_DENSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "    ),\n",
    "    \"liquid_prandtl\": prandtl(\n",
    "        dynamic_viscosity=LIQUID_DYNAMIC_VISCOSITY,\n",
    "        isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "    ),\n",
    "    \"bubble_jakob\": jakob(\n",
    "        liquid_density=LIQUID_DENSITY,\n",
    "        vapor_density=VAPOR_DENSITY,\n",
    "        liquid_isobaric_specific_heat=LIQUID_ISOBARIC_SPECIFIC_HEAT,\n",
    "        subcooling=subcooling,\n",
    "        latent_heat_of_vaporization=LATENT_HEAT_OF_VAPORIZATION,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def get_corrs(df: DataFrame, kind: Corr) -> DataFrame:\n",
    "    \"\"\"Get correlations.\"\"\"\n",
    "    return df.assign(**{\n",
    "        C.corr[label](): (\n",
    "            corr.expr(**{\n",
    "                kwd: value\n",
    "                for kwd, value in {\n",
    "                    **constants,\n",
    "                    \"Re_b\": df[C.bub_reynolds()],\n",
    "                    \"Re_b0\": df[C.bub_reynolds0()],\n",
    "                    \"Fo_0\": df[C.bub_fourier()],\n",
    "                    **({} if kind == \"beta\" else {\"beta\": df[C.bub_beta()]}),\n",
    "                }.items()\n",
    "                if kwd in Signature.from_callable(corr.expr).parameters\n",
    "            })\n",
    "        )\n",
    "        for label, corr in (\n",
    "            beta_correlations if kind == \"beta\" else nusselt_correlations\n",
    "        ).items()\n",
    "    })\n",
    "\n",
    "\n",
    "# def get_error(df: DataFrame, kind: Corr) -> DataFrame:\n",
    "#     \"\"\"Get absolute error.\"\"\"\n",
    "#     corrs = [c() for c in C.corr.values()]\n",
    "#     exp = C.bub_beta() if kind == \"beta\" else C.bub_nusselt()\n",
    "#     return (\n",
    "#         df.set_index([C.bub_fourier(), C.bub()])[[exp, *corrs]]\n",
    "#         .pipe(lambda df: df.assign(**{c: abs(df[exp] - df[c]) for c in corrs}))\n",
    "#         .reset_index()\n",
    "#     )\n",
    "\n",
    "\n",
    "def get_error(df: DataFrame, kind: Corr) -> DataFrame:\n",
    "    \"\"\"Get relative error.\"\"\"\n",
    "    corrs = [c() for c in C.corr.values()]\n",
    "    exp = C.bub_beta() if kind == \"beta\" else C.bub_nusselt()\n",
    "    return (\n",
    "        df.set_index([C.bub_fourier(), C.bub()])[[exp, *corrs]]\n",
    "        .pipe(lambda df: df.assign(**{c: abs(df[exp] - df[c]) / df[c] for c in corrs}))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def set_group_legend(ax):\n",
    "    \"\"\"Set legend for correlation groups.\"\"\"\n",
    "    legend = ax.legend(\n",
    "        [\n",
    "            {lab: h for h, lab in zip(*ax.get_legend_handles_labels(), strict=False)}[\n",
    "                lab\n",
    "            ]\n",
    "            for lab in GROUP_ORDER\n",
    "        ],\n",
    "        GROUP_ORDER,\n",
    "    )\n",
    "    for handle in legend.legend_handles:  # pyright: ignore[reportAttributeAccessIssue]\n",
    "        handle.set_alpha(1.0)\n",
    "\n",
    "\n",
    "def preview(\n",
    "    df: DfOrS_T,\n",
    "    cols: Iterable[Col] | None = None,\n",
    "    index: Col | None = None,\n",
    "    f: Callable[[DfOrS_T], DfOrS_T] | None = None,\n",
    "    ncol: int = 0,\n",
    ") -> DfOrS_T:\n",
    "    \"\"\"Preview a dataframe in the notebook.\"\"\"\n",
    "    # fmt: off\n",
    "    if df.empty:\n",
    "        display(df)\n",
    "        return df\n",
    "    if isinstance(df, Series):\n",
    "        def _f(df): return (f(df) if f else df).head(16)\n",
    "    elif C.bub() in df.columns:\n",
    "        def _f(df): return (_df := f(df) if f else df).groupby(C.bub(), **GBC)[_df.columns].head(4).head(16)  # pyright: ignore[reportRedeclaration]\n",
    "    else:\n",
    "        def _f(df): return (f(df) if f else df).head(4).head(16)\n",
    "    # fmt: on\n",
    "    df = params.preview(cols=cols, df=df, index=index, f=_f, ncol=ncol)  # pyright: ignore[reportArgumentType]\n",
    "    return df\n",
    "\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.tracks = preview(\n",
    "    ncol=12,\n",
    "    cols=C.tracks,\n",
    "    df=link(\n",
    "        # ? TrackPy expects certain column names\n",
    "        f=objects.rename(columns={c(): c.source.raw for c in cols_to_link}),  # pyright: ignore[reportCallIssue]\n",
    "        search_range=SEARCH_RANGE,\n",
    "        memory=MEMORY,\n",
    "    )\n",
    "    .pipe(rename, cols_to_link)  # ? Back to our names\n",
    "    .pipe(C.bub.rename)\n",
    "    .assign(**{\n",
    "        C.bub_visible_frames(): lambda df: (\n",
    "            df.groupby(C.bub(), **GBC)[C.bub()].transform(\"count\") * frames_per_step\n",
    "        )\n",
    "    })\n",
    "    .pipe(convert, [C.x, C.y, C.diameter, C.radius_of_gyration], U)\n",
    "    .sort_values(\n",
    "        [C.bub_visible_frames(), C.bub(), C.frame()], ascending=[False, True, True]\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): (lambda df: df.groupby(C.bub(), **GBC).ngroup()),\n",
    "        C.u(): lambda df: get_delta(df, C.u),\n",
    "        C.v(): lambda df: get_delta(df, C.v),\n",
    "        C.distance(): lambda df: linalg.norm(df[[C.u(), C.v()]].abs(), axis=1),\n",
    "    })\n",
    "    .pipe(convert, [C.bub_visible], U),\n",
    ")\n",
    "print(f\"Found {data.dfs.tracks[C.bub()].nunique()} bubbles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.bubbles = preview(\n",
    "    ncol=12,\n",
    "    cols=C.bubbles,\n",
    "    # ? Find rows corresponding to stagnant or invalid bubbles\n",
    "    df=data.dfs.tracks.pipe(lambda df: df[df[C.bub_visible()] > MINIMUM_LIFETIME])\n",
    "    .groupby(C.bub(), **GBC)[data.dfs.tracks.columns]\n",
    "    .apply(\n",
    "        # ? Don't assign any other columns until invalid rows have been filtered out\n",
    "        lambda df: df.assign(**{\n",
    "            \"bubble_visible_y\": lambda df: df[C.y()].pipe(get_init),\n",
    "            # ? Initial y position is close to the surface\n",
    "            \"began\": lambda df: df[\"bubble_visible_y\"] > Y_SURFACE_THRESHOLD,\n",
    "            # ? When the bubble gets far enough away from the surface\n",
    "            \"departed\": lambda df: df[C.y()] < Y_DEPARTURE_THRESHOLD,\n",
    "        })\n",
    "    )\n",
    "    # ? Filter out invalid rows\n",
    "    .pipe(lambda df: df[df[\"began\"] & df[\"departed\"]])\n",
    "    .pipe(limit_group_size, C.bub(), 1)\n",
    "    # ? Groupby again after filtering out invalid rows\n",
    "    .groupby(C.bub(), **GBC)[data.dfs.tracks.columns]\n",
    "    # ? Now columns that depend on the initial row (*.iat[0]) can be assigned\n",
    "    .apply(\n",
    "        lambda df: df.assign(**{\n",
    "            C.bub_time(): (\n",
    "                lambda df: df[C.time_elapsed()] - df[C.time_elapsed()].iat[0]\n",
    "            ),\n",
    "            C.bub_lifetime(): lambda df: (\n",
    "                df[C.bub_time()].iat[-1] - df[C.bub_time()].pipe(get_init)\n",
    "            ),\n",
    "            C.bub_t0(): lambda df: df[C.bub_time()].pipe(get_init),\n",
    "            C.bub_x0(): lambda df: df[C.x()].pipe(get_init),\n",
    "            C.bub_y0(): lambda df: df[C.y()].pipe(get_init),\n",
    "            C.bub_d0(): lambda df: df[C.diameter()].pipe(get_init),\n",
    "            C.bub_u0(): lambda df: df[C.u()].pipe(get_init),\n",
    "            C.bub_v0(): lambda df: df[C.v()].pipe(get_init),\n",
    "            C.max_diam(): lambda df: df[C.diameter()].max(),\n",
    "            C.diam_rate_of_change(): lambda df: gradient(\n",
    "                df[C.diameter()], df[C.bub_time()]\n",
    "            ),\n",
    "        })\n",
    "    ),\n",
    ")\n",
    "print(f\"{data.dfs.bubbles[C.bub()].nunique()} bubbles remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.plots.multi, axs = subplot_mosaic([\n",
    "    [C.y(), C.v()],\n",
    "    [C.diameter(), C.diam_rate_of_change()],\n",
    "])\n",
    "scale_figure(data.plots.multi)\n",
    "for plot, ax in axs.items():\n",
    "    palette, tracks_data = get_cat_colorbar(\n",
    "        ax, C.bub(), TRACKS_PALETTE, data.dfs.bubbles\n",
    "    )\n",
    "    scatterplot(\n",
    "        ax=ax,\n",
    "        edgecolor=\"none\",\n",
    "        s=TRACKS_SIZE,\n",
    "        alpha=TRACKS_ALPHA,\n",
    "        x=C.bub_time(),\n",
    "        y=plot,  # pyright: ignore[reportArgumentType] 1.1.356\n",
    "        hue=C.bub(),\n",
    "        legend=False,\n",
    "        palette=palette,\n",
    "        data=tracks_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.dst = preview(\n",
    "    cols=C.dests,\n",
    "    df=data.dfs.bubbles.assign(**{\n",
    "        C.bub_reynolds(): lambda df: reynolds(\n",
    "            velocity=abs(df[C.v()]),\n",
    "            characteristic_length=df[C.diameter()],\n",
    "            kinematic_viscosity=constants[\"liquid_kinematic_viscosity\"],\n",
    "        ),\n",
    "        C.bub_reynolds0(): lambda df: df.groupby(C.bub(), **GBC)[\n",
    "            C.bub_reynolds()\n",
    "        ].transform(get_init),\n",
    "        C.bub_fourier(): fourier(\n",
    "            initial_bubble_diameter=data.dfs.bubbles[C.bub_d0()],\n",
    "            liquid_thermal_diffusivity=constants[\"liquid_thermal_diffusivity\"],\n",
    "            time=data.dfs.bubbles[C.bub_time()],\n",
    "        ),\n",
    "        C.bub_nusselt(): nusselt(  # Nu_c\n",
    "            heat_transfer_coefficient=-(\n",
    "                2\n",
    "                * VAPOR_DENSITY\n",
    "                * LATENT_HEAT_OF_VAPORIZATION\n",
    "                / subcooling\n",
    "                * data.dfs.bubbles[C.diam_rate_of_change()]\n",
    "            ),\n",
    "            characteristic_length=data.dfs.bubbles[C.diameter()],\n",
    "            thermal_conductivity=LIQUID_THERMAL_CONDUCTIVITY,\n",
    "        ),\n",
    "        C.bub_beta(): (lambda df: df[C.diameter()] / df[C.bub_d0()]),\n",
    "    }),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.beta = preview(\n",
    "    cols=C.corr_beta, df=data.dfs.dst.pipe(get_corrs, kind=\"beta\"), ncol=6\n",
    ")\n",
    "data.dfs.nusselt = preview(\n",
    "    cols=C.corr_nusselt, df=data.dfs.dst.pipe(get_corrs, kind=\"nusselt\"), ncol=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.beta_err = preview(\n",
    "    cols=C.corr_beta, df=data.dfs.beta.pipe(get_error, kind=\"beta\"), ncol=6\n",
    ")\n",
    "\n",
    "data.plots.beta_err, ax = subplots()\n",
    "ax.set_ylabel(C.bub_beta())\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_beta(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        melt(\n",
    "            data.dfs.beta_err.set_index(C.bub_fourier())[\n",
    "                [c() for c in C.corr.values()]\n",
    "            ],\n",
    "            var_name=\"Correlation\",\n",
    "            value_name=C.bub_beta(),\n",
    "            value_vars=[c() for c in C.corr.values()],\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .assign(**{\n",
    "            C.bub_fourier(): lambda df: df.index,\n",
    "            \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data.dfs.nusselt_err = preview(\n",
    "    cols=C.corr_nusselt, df=data.dfs.nusselt.pipe(get_error, kind=\"nusselt\"), ncol=6\n",
    ")\n",
    "\n",
    "\n",
    "data.plots.nusselt_err, ax = subplots()\n",
    "ax.set_ylabel(C.bub_nusselt())\n",
    "ax.set_ylim(1e-5, 1e5)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_fourier(),\n",
    "    y=C.bub_nusselt(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        melt(\n",
    "            data.dfs.nusselt_err.set_index(C.bub_fourier())[\n",
    "                [c() for c in C.corr.values()]\n",
    "            ],\n",
    "            var_name=\"Correlation\",\n",
    "            value_name=C.bub_nusselt(),\n",
    "            value_vars=[c() for c in C.corr.values()],\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .assign(**{\n",
    "            C.bub_fourier(): lambda df: df.index,\n",
    "            \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "beta_mae = data.dfs.beta.groupby(C.bub(), **GBC)[[c() for c in C.corr.values()]].apply(\n",
    "    lambda df: df.sum() / len(df)\n",
    ")\n",
    "beta_mae_pivoted = (\n",
    "    melt(\n",
    "        beta_mae.set_index(C.bub()),\n",
    "        var_name=\"Correlation\",\n",
    "        value_name=C.bub_beta(),\n",
    "        value_vars=[c() for c in C.corr.values()],\n",
    "        ignore_index=False,\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): lambda df: df.index,\n",
    "        \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(\"Group\")\n",
    ")\n",
    "nusselt_mae = data.dfs.nusselt.groupby(C.bub(), **GBC)[\n",
    "    [c() for c in C.corr.values()]\n",
    "].apply(lambda df: df.sum() / len(df))\n",
    "nusselt_mae_pivoted = (\n",
    "    melt(\n",
    "        nusselt_mae.set_index(C.bub()),\n",
    "        var_name=\"Correlation\",\n",
    "        value_name=C.bub_nusselt(),\n",
    "        value_vars=[c() for c in C.corr.values()],\n",
    "        ignore_index=False,\n",
    "    )\n",
    "    .assign(**{\n",
    "        C.bub(): lambda df: df.index,\n",
    "        \"Group\": lambda df: df[\"Correlation\"].map(groups),\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    "    .sort_values(\"Group\")\n",
    ")\n",
    "\n",
    "data.plots.mae, ax = subplots()\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "scatterplot(\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    hue_order=GROUP_DRAW_ORDER,\n",
    "    s=TRACKS_SIZE,\n",
    "    alpha=TRACKS_ALPHA,\n",
    "    palette=\"tab10\",\n",
    "    x=C.bub_beta(),\n",
    "    y=C.bub_nusselt(),\n",
    "    hue=\"Group\",\n",
    "    data=(\n",
    "        merge_ordered(\n",
    "            beta_mae_pivoted.drop(columns=\"Group\").set_index(C.bub()),\n",
    "            nusselt_mae_pivoted.drop(columns=\"Group\").set_index(C.bub()),\n",
    "            on=[C.bub(), \"Correlation\"],\n",
    "        )\n",
    "        .assign(**{\"Group\": lambda df: df[\"Correlation\"].map(groups)})\n",
    "        .sort_values(\"Group\", key=GROUP_SORTER)\n",
    "    ),\n",
    ")\n",
    "set_group_legend(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "parameters": {
    "product": "C:/Users/Blake/Code/mine/boilercv/data/docs/study_the_fit_of_bubble_collapse_correlations/prove_the_concept/23-07-13T14_full_video.ipynb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
